{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Loader.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "91bf5067d6924deaad2cafbcb651ea22": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_61369549c893411ebbc1b64d88ddb1c6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4cc64377183449c580244b12f78fd7f9",
              "IPY_MODEL_d8267ffc679b4dc2b569886572966b81"
            ]
          }
        },
        "61369549c893411ebbc1b64d88ddb1c6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cc64377183449c580244b12f78fd7f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eacad8cd4b1b4d6499b36354540d3658",
            "_dom_classes": [],
            "description": " 10%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 100000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10412,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_47b3b0c910954aec875dcf435b0ee999"
          }
        },
        "d8267ffc679b4dc2b569886572966b81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b91d34ce1ba54ba79f057684a9b603c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10412/100000 [00:53&lt;05:24, 275.70it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d599c5de794470cb5cd258102ca4bf6"
          }
        },
        "eacad8cd4b1b4d6499b36354540d3658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "47b3b0c910954aec875dcf435b0ee999": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b91d34ce1ba54ba79f057684a9b603c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d599c5de794470cb5cd258102ca4bf6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazio/NMAs/blob/main/src/Data_Loader_Chetan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji-aTo7SA1AB"
      },
      "source": [
        "#Exploratory Data Analysis of Stringer Dataset \n",
        "@authors: Simone Azeglio, Chetan Dhulipalla , Khalid Saifullah \n",
        "\n",
        "\n",
        "Part of the code here has been taken from [Neuromatch Academy's Computational Neuroscience Course](https://compneuro.neuromatch.io/projects/neurons/README.html), and specifically from [this notebook](https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/projects/neurons/load_stringer_spontaneous.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x2LTF6oe-U8R"
      },
      "source": [
        "# to do list\n",
        "\n",
        "1. custom normalization: dividing by mean value per neuron\n",
        "1a. downsampling: convolve then downsample by 5\n",
        "2. training validation split: withhold last 20 percent of time series for testing\n",
        "3. RNN for each layer: a way to capture the dynamics inside each layer instead of capturing extra dynamics from inter-layer interactions. it will be OK to compare the different RNNs. maintain same neuron count in each layer to reduce potential bias \n",
        "4. layer weight regularization: L2 \n",
        "5. early stopping , dropout?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs7e5ppCMYCK"
      },
      "source": [
        "## Loading of Stringer spontaneous data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0nA90QhJurD",
        "cellView": "form"
      },
      "source": [
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = \"stringer_spontaneous.npy\"\n",
        "url = \"https://osf.io/dpqaj/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgbdwXWDSUpO",
        "cellView": "form"
      },
      "source": [
        "#@title Import matplotlib and set defaults\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRWWoEX0-sYp"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulJ34TyRZo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "430fc3c8-703b-425c-a827-f6cf9b68fa34"
      },
      "source": [
        "#@title Data loading\n",
        "import numpy as np\n",
        "dat = np.load('stringer_spontaneous.npy', allow_pickle=True).item()\n",
        "print(dat.keys())"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['sresp', 'run', 'beh_svd_time', 'beh_svd_mask', 'stat', 'pupilArea', 'pupilCOM', 'xyz'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KGn2iJGmFpLC"
      },
      "source": [
        "# functions \n",
        "\n",
        "def moving_avg(array, factor = 5):\n",
        "  \"\"\"Reducing the number of compontents by averaging of N = factor\n",
        "  subsequent elements of array\"\"\"\n",
        "  zeros_ = np.zeros((array.shape[0], 2))\n",
        "  array = np.hstack((array, zeros_))\n",
        "\n",
        "  array = np.reshape(array, (array.shape[0],  int(array.shape[1]/factor), factor))\n",
        "  array = np.mean(array, axis = 2)\n",
        "\n",
        "  return array"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdjYTZeV-yhR"
      },
      "source": [
        "## Extracting Data for RNN (or LFADS)\n",
        "The first problem to address is that for each layer we don't have the exact same number of neurons. We'd like to have a single RNN encoding all the different layers activities, to make it easier we can take the number of neurons ($N_{neurons} = 1131$ of the least represented class (layer) and level out each remaining class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEy_qiyKY1xG"
      },
      "source": [
        "# Extract labels from z - coordinate\n",
        "from sklearn import preprocessing\n",
        "x, y, z = dat['xyz']\n",
        "\n",
        "le = preprocessing.LabelEncoder()\n",
        "labels = le.fit_transform(z)\n",
        "### least represented class (layer with less neurons)\n",
        "n_samples = np.histogram(labels, bins=9)[0][-1]"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb3M2PSOZpMW"
      },
      "source": [
        "### Data for LFADS / RNN \n",
        "import pandas as pd \n",
        "dataSet = pd.DataFrame(dat[\"sresp\"])\n",
        "dataSet[\"label\"] = labels "
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYThvxV-2Nl6"
      },
      "source": [
        "# it can be done in one loop ... \n",
        "data_ = []\n",
        "for i in range(0, 9):\n",
        "  data_.append(dataSet[dataSet[\"label\"] == i].sample(n = n_samples).iloc[:,:-1])\n",
        "\n",
        "dataRNN = np.zeros((n_samples*9, dataSet.shape[1]-1))\n",
        "for i in range(0,9):\n",
        "  dataRNN[n_samples*i:n_samples*(i+1), :] = data_[i]\n",
        "\n",
        "## shuffling for training purposes\n",
        "\n",
        "#np.random.shuffle(dataRNN)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WAqcnCTrZAz"
      },
      "source": [
        "unshuffled = np.array(data_)"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "680ch36_-e0m",
        "cellView": "form"
      },
      "source": [
        "#@title Convolutions code\n",
        "\n",
        "# convolution moving average\n",
        "\n",
        "# kernel_length = 50\n",
        "# averaging_kernel = np.ones(kernel_length) / kernel_length\n",
        "\n",
        "# dataRNN.shape\n",
        "\n",
        "# avgd_dataRNN = list()\n",
        "\n",
        "# for neuron in dataRNN:\n",
        "#   avgd_dataRNN.append(np.convolve(neuron, averaging_kernel))\n",
        "\n",
        "# avg_dataRNN = np.array(avgd_dataRNN)\n",
        "\n",
        "# print(avg_dataRNN.shape)"
      ],
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "63S3144a31FI",
        "cellView": "form"
      },
      "source": [
        "# @title Z Score Code \n",
        "\n",
        "\n",
        "# from scipy.stats import zscore\n",
        "\n",
        "\n",
        "# neuron = 500\n",
        "\n",
        "# scaled_all = zscore(avg_dataRNN)\n",
        "# scaled_per_neuron = zscore(avg_dataRNN[neuron, :])\n",
        "\n",
        "# scaled_per_layer = list()\n",
        "\n",
        "# for layer in unshuffled:\n",
        "#   scaled_per_layer.append(zscore(layer))\n",
        "\n",
        "# scaled_per_layer = np.array(scaled_per_layer)\n",
        "\n",
        "\n",
        "\n",
        "# plt.plot(avg_dataRNN[neuron, :])\n",
        "# plt.plot(avg_dataRNN[2500, :])\n",
        "# plt.figure()\n",
        "# plt.plot(dataRNN[neuron, :])\n",
        "# plt.figure()\n",
        "# plt.plot(scaled_all[neuron, :])\n",
        "# plt.plot(scaled_per_neuron)\n",
        "# plt.figure()\n",
        "# plt.plot(scaled_per_layer[0,neuron,:])\n"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE-4w_4V-Gzx"
      },
      "source": [
        "# custom normalization\n",
        "\n",
        "normed_dataRNN = list()\n",
        "for neuron in dataRNN:\n",
        "  normed_dataRNN.append(neuron / neuron.mean())\n",
        "normed_dataRNN = np.array(normed_dataRNN)\n",
        "\n",
        "# downsampling and averaging \n",
        "\n",
        "avgd_normed_dataRNN = moving_avg(normed_dataRNN, factor=5)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SeNxo6vsv1Oq"
      },
      "source": [
        "issue: does the individual scaling by layer introduce bias that may artificially increase performance of the network?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MrXC5QIiyhJ"
      },
      "source": [
        "## Data Loader \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "255tz5iqmSq1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "467WOHhtmXmb"
      },
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dcb5vW2joVW_"
      },
      "source": [
        "# set the seed\n",
        "np.random.seed(42)\n",
        "\n",
        "# number of neurons \n",
        "NN = dataRNN.shape[0]\n",
        "\n",
        "# let's use 270 latent components\n",
        "ncomp = 10"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bXJPQdu17Ns5",
        "outputId": "da51f408-d334-4c5f-8afc-56b6275a3cb6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# swapping the axes to maintain consistency with seq2seq notebook in the following code - the network takes all the neurons at a time step as input, not just one neuron\n",
        "\n",
        "avgd_normed_dataRNN = np.swapaxes(avgd_normed_dataRNN, 0, 1)\n",
        "avgd_normed_dataRNN.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1404, 10179)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Prl0OxLZkka9"
      },
      "source": [
        "frac = 5/6\n",
        "#x1 = torch.from_numpy(dataRNN[:,:int(frac*dataRNN.shape[1])]).to(device).float().unsqueeze(0)\n",
        "#x2 = torch.from_numpy(dataRNN[:,int(frac*dataRNN.shape[1]):]).to(device).float().unsqueeze(0)\n",
        "x1 = torch.from_numpy(avgd_normed_dataRNN[:,:50]).to(device).float().unsqueeze(0)\n",
        "x2 = torch.from_numpy(avgd_normed_dataRNN[:,:50]).to(device).float().unsqueeze(0)\n",
        "\n",
        "NN1 = x1.shape[-1]\n",
        "NN2 = x2.shape[-1]"
      ],
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "01IvhjPzk-Jw"
      },
      "source": [
        "class Net(nn.Module):\n",
        "  def __init__(self, ncomp, NN1, NN2, bidi=True):\n",
        "    super(Net, self).__init__()\n",
        "\n",
        "    # play with some of the options in the RNN!\n",
        "    self.rnn = nn.RNN(NN1, ncomp, num_layers = 1, dropout = 0,\n",
        "                      bidirectional = bidi, nonlinearity = 'tanh')\n",
        "    self.fc = nn.Linear(ncomp, NN2)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    y = self.rnn(x)[0]\n",
        "\n",
        "    if self.rnn.bidirectional:\n",
        "      # if the rnn is bidirectional, it concatenates the activations from the forward and backward pass\n",
        "      # we want to add them instead, so as to enforce the latents to match between the forward and backward pass\n",
        "      q = (y[:, :, :ncomp] + y[:, :, ncomp:])/2\n",
        "    else:\n",
        "      q = y\n",
        "\n",
        "    # the softplus function is just like a relu but it's smoothed out so we can't predict 0\n",
        "    # if we predict 0 and there was a spike, that's an instant Inf in the Poisson log-likelihood which leads to failure\n",
        "    #z = F.softplus(self.fc(q), 10)\n",
        "    z = self.fc(q)\n",
        "\n",
        "    return z, q"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQGEVQaGmwV6"
      },
      "source": [
        "# we initialize the neural network\n",
        "net = Net(ncomp, NN1, NN2, bidi = True).to(device)\n",
        "\n",
        "# special thing:  we initialize the biases of the last layer in the neural network\n",
        "# we set them as the mean firing rates of the neurons.\n",
        "# this should make the initial predictions close to the mean, because the latents don't contribute much\n",
        "net.fc.bias.data[:] = x1.mean(axis = (1,2))\n",
        "\n",
        "# we set up the optimizer. Adjust the learning rate if the training is slow or if it explodes.\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=.02)"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SzvKjuTvmwYa"
      },
      "source": [
        "# forward check \n",
        "# net(x1)"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hlfx8Ltp5jJ"
      },
      "source": [
        "## Training "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjzD06B9ta3n"
      },
      "source": [
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "91bf5067d6924deaad2cafbcb651ea22",
            "61369549c893411ebbc1b64d88ddb1c6",
            "4cc64377183449c580244b12f78fd7f9",
            "d8267ffc679b4dc2b569886572966b81",
            "eacad8cd4b1b4d6499b36354540d3658",
            "47b3b0c910954aec875dcf435b0ee999",
            "b91d34ce1ba54ba79f057684a9b603c8",
            "5d599c5de794470cb5cd258102ca4bf6"
          ]
        },
        "id": "aNG8yY9fp6sg",
        "outputId": "5ca9a014-bf3a-4f2c-c97b-cf80469ac0fe"
      },
      "source": [
        "# you can keep re-running this cell if you think the cost might decrease further\n",
        "\n",
        "cost = nn.MSELoss()\n",
        "\n",
        "niter = 100000\n",
        "for k in tqdm(range(niter)):\n",
        "  # the network outputs the single-neuron prediction and the latents\n",
        "  z, y = net(x1)\n",
        "\n",
        "  # our cost\n",
        "  loss = cost(z, x2)\n",
        "\n",
        "  # train the network as usual\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "\n",
        "  if k % 250 == 0:\n",
        "    print(f' iteration {k}, cost {loss.item():.4f}')"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91bf5067d6924deaad2cafbcb651ea22",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=100000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            " iteration 0, cost 0.2433\n",
            " iteration 250, cost 0.2435\n",
            " iteration 500, cost 0.2439\n",
            " iteration 750, cost 0.2459\n",
            " iteration 1000, cost 0.2431\n",
            " iteration 1250, cost 0.2430\n",
            " iteration 1500, cost 0.2431\n",
            " iteration 1750, cost 0.2435\n",
            " iteration 2000, cost 0.2428\n",
            " iteration 2250, cost 0.2430\n",
            " iteration 2500, cost 0.2435\n",
            " iteration 2750, cost 0.2431\n",
            " iteration 3000, cost 0.2430\n",
            " iteration 3250, cost 0.2447\n",
            " iteration 3500, cost 0.2439\n",
            " iteration 3750, cost 0.2442\n",
            " iteration 4000, cost 0.2466\n",
            " iteration 4250, cost 0.2431\n",
            " iteration 4500, cost 0.2443\n",
            " iteration 4750, cost 0.2438\n",
            " iteration 5000, cost 0.2429\n",
            " iteration 5250, cost 0.2432\n",
            " iteration 5500, cost 0.2445\n",
            " iteration 5750, cost 0.2432\n",
            " iteration 6000, cost 0.2440\n",
            " iteration 6250, cost 0.2431\n",
            " iteration 6500, cost 0.2449\n",
            " iteration 6750, cost 0.2428\n",
            " iteration 7000, cost 0.2429\n",
            " iteration 7250, cost 0.2430\n",
            " iteration 7500, cost 0.2429\n",
            " iteration 7750, cost 0.2456\n",
            " iteration 8000, cost 0.2434\n",
            " iteration 8250, cost 0.2429\n",
            " iteration 8500, cost 0.2448\n",
            " iteration 8750, cost 0.2438\n",
            " iteration 9000, cost 0.2431\n",
            " iteration 9250, cost 0.2445\n",
            " iteration 9500, cost 0.2439\n",
            " iteration 9750, cost 0.2429\n",
            " iteration 10000, cost 0.2429\n",
            " iteration 10250, cost 0.2435\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-96-24e13ccdf4ed>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;31m# train the network as usual\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m   \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jryOMKdDJoEh"
      },
      "source": [
        "test = net()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HY_xlS8k7BF8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}