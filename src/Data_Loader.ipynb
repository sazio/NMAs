{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_Loader.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOsv4JdVdE7zuDSQZqil2q0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sazio/NMAs/blob/main/src/Data_Loader.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWEtXADSgNWB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ji-aTo7SA1AB"
      },
      "source": [
        "#Exploratory Data Analysis of Stringer Dataset \n",
        "@authors: Simone Azeglio, Chetan Dhulipalla , Khalid Saifullah \n",
        "\n",
        "\n",
        "Part of the code here has been taken from [Neuromatch Academy's Computational Neuroscience Course](https://compneuro.neuromatch.io/projects/neurons/README.html), and specifically from [this notebook](https://colab.research.google.com/github/NeuromatchAcademy/course-content/blob/master/projects/neurons/load_stringer_spontaneous.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vs7e5ppCMYCK"
      },
      "source": [
        "## Loading of Stringer spontaneous data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0nA90QhJurD",
        "cellView": "form"
      },
      "source": [
        "#@title Data retrieval\n",
        "import os, requests\n",
        "\n",
        "fname = \"stringer_spontaneous.npy\"\n",
        "url = \"https://osf.io/dpqaj/download\"\n",
        "\n",
        "if not os.path.isfile(fname):\n",
        "  try:\n",
        "    r = requests.get(url)\n",
        "  except requests.ConnectionError:\n",
        "    print(\"!!! Failed to download data !!!\")\n",
        "  else:\n",
        "    if r.status_code != requests.codes.ok:\n",
        "      print(\"!!! Failed to download data !!!\")\n",
        "    else:\n",
        "      with open(fname, \"wb\") as fid:\n",
        "        fid.write(r.content)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FgbdwXWDSUpO",
        "cellView": "form"
      },
      "source": [
        "#@title Import matplotlib and set defaults\n",
        "from matplotlib import rcParams \n",
        "from matplotlib import pyplot as plt\n",
        "rcParams['figure.figsize'] = [20, 4]\n",
        "rcParams['font.size'] =15\n",
        "rcParams['axes.spines.top'] = False\n",
        "rcParams['axes.spines.right'] = False\n",
        "rcParams['figure.autolayout'] = True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRWWoEX0-sYp"
      },
      "source": [
        "## Exploratory Data Analysis (EDA)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulJ34TyRZo6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "381951e3-d080-48a1-cb82-374cfefdd1da"
      },
      "source": [
        "#@title Data loading\n",
        "import numpy as np\n",
        "dat = np.load('stringer_spontaneous.npy', allow_pickle=True).item()\n",
        "print(dat.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['sresp', 'run', 'beh_svd_time', 'beh_svd_mask', 'stat', 'pupilArea', 'pupilCOM', 'xyz'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdjYTZeV-yhR"
      },
      "source": [
        "## Extracting Data for RNN (or LFADS)\n",
        "The first problem to address is that for each layer we don't have the exact same number of neurons. We'd like to have a single RNN encoding all the different layers activities, to make it easier we can take the number of neurons ($N_{neurons} = 1131$ of the least represented class (layer) and level out each remaining class. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEy_qiyKY1xG"
      },
      "source": [
        "# Extract labels from z - coordinate\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "labels = le.fit_transform(z)\n",
        "### least represented class (layer with less neurons)\n",
        "n_samples = np.histogram(labels, bins=9)[0][-1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lb3M2PSOZpMW"
      },
      "source": [
        "### Data for LFADS / RNN \n",
        "import pandas as pd \n",
        "dataSet = pd.DataFrame(dat[\"sresp\"])\n",
        "dataSet[\"label\"] = labels "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYThvxV-2Nl6"
      },
      "source": [
        "# it can be done in one loop ... \n",
        "data_ = []\n",
        "for i in range(0, 9):\n",
        "  data_.append(dataSet[dataSet[\"label\"] == i].sample(n = n_samples).iloc[:,:-1])\n",
        "\n",
        "dataRNN = np.zeros((n_samples*9, dataSet.shape[1]-1))\n",
        "for i in range(0,9):\n",
        "  dataRNN[n_samples*i:n_samples*(i+1), :] = data_[i]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJe0Kh3l7za6"
      },
      "source": [
        "#np.save(\"dataRNN.npy\", dataRNN) # ~533 MB (we can eventually consider using float16 in case)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0MrXC5QIiyhJ"
      },
      "source": [
        "## Data Loader \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0tm_ew-ngciD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}